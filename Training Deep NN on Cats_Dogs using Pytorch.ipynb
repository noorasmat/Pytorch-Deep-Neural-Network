{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mTgWtixZTs3X"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "6tAvkzBXM_4o",
    "outputId": "42c8f10f-6807-4df9-a787-5fec549fc983"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /DataSets\n"
     ]
    }
   ],
   "source": [
    "# Load the Drive helper and mount\n",
    "from google.colab import drive\n",
    "\n",
    "# This will prompt for authorization.\n",
    "drive.mount('/DataSets')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-AlNepDerhFZ",
    "outputId": "ca14a86a-7901-4980-82eb-d7fa77dd07bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Assignment 1.zip'  'Assignment 2.zip'\n"
     ]
    }
   ],
   "source": [
    "!ls \"/DataSets/My Drive/DataSets\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4krHJYvEqUvm"
   },
   "outputs": [],
   "source": [
    "import zipfile as zf\n",
    "files = zf.ZipFile(\"/DataSets/My Drive/DataSets/Assignment 1.zip\", 'r')\n",
    "files.extractall('/DataSetExtracted')\n",
    "files.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "aw-jyXuXE3X-",
    "outputId": "9caf77a1-88ae-4f0d-c071-f664155c4f61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Assignment 1.docx', 'dogs-vs-cats.zip']"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('/DataSetExtracted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oxWD54tCyCTh"
   },
   "outputs": [],
   "source": [
    "import zipfile as zf\n",
    "files = zf.ZipFile('/DataSetExtracted/dogs-vs-cats.zip', 'r')\n",
    "files.extractall('/DataSetExtracted/Dogs-vs-cats/')\n",
    "files.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AIul-dP0A1QS"
   },
   "outputs": [],
   "source": [
    "data_dir=('/DataSetExtracted/Dogs-vs-cats/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wqhPGaoM1ko0"
   },
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IBOULxeR1ko5"
   },
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "num_epochs = 2\n",
    "num_classes = 2\n",
    "batch_size = 10\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "513d77fe38d62ff991eacdcf29a8640db7f20689",
    "colab": {},
    "colab_type": "code",
    "id": "wcyuvZQd1kpK"
   },
   "outputs": [],
   "source": [
    "# TODO: Define transforms for the training data and testing data\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(180),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "# Pass transforms in here, then run the next cell to see how the transforms look\n",
    "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=10, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dZwM3mmY1kpN"
   },
   "outputs": [],
   "source": [
    "# Convolutional neural network (two convolutional layers)\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size=(5, 5), stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size=(5, 5), stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size=(3, 3), padding=1)\n",
    "        self.fc1 = nn.Linear(in_features= 64 * 6 * 6, out_features=500)\n",
    "        self.fc2 = nn.Linear(in_features=500, out_features=50)\n",
    "        self.fc3 = nn.Linear(in_features=50, out_features=2)\n",
    "        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = F.max_pool2d(X, 2)\n",
    "        \n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X, 2)\n",
    "        \n",
    "        X = F.relu(self.conv3(X))\n",
    "        X = F.max_pool2d(X, 2)\n",
    "        \n",
    "#         print(X.shape)\n",
    "        X = X.view(X.shape[0], -1)\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = self.fc3(X)\n",
    "        \n",
    "#         X = torch.sigmoid(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "iUTNI5ea4-_V",
    "outputId": "5964ae7f-f153-475c-90f5-b88697f7f46e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.current_device()\n",
    "torch.cuda.device(0)\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.device_count()\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "mHZkCRHV5lJq",
    "outputId": "640651c5-097b-4631-af5c-0d19550d6ca9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla T4'"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kBvLYq0Z3UL4"
   },
   "outputs": [],
   "source": [
    " # Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LOOyYnBX1kpR"
   },
   "outputs": [],
   "source": [
    "model = Net(num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AV14vP7g8AXu"
   },
   "outputs": [],
   "source": [
    "model = Net(num_classes).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5nbeTVNT1kpV"
   },
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "R6j22sl81kpY",
    "outputId": "7a1cf1db-7f64-464e-a03c-7a9ab901d873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [10/901], Loss: 0.7907\n",
      "Epoch [1/2], Step [20/901], Loss: 0.7214\n",
      "Epoch [1/2], Step [30/901], Loss: 0.6993\n",
      "Epoch [1/2], Step [40/901], Loss: 0.6645\n",
      "Epoch [1/2], Step [50/901], Loss: 0.5513\n",
      "Epoch [1/2], Step [60/901], Loss: 0.6770\n",
      "Epoch [1/2], Step [70/901], Loss: 0.5540\n",
      "Epoch [1/2], Step [80/901], Loss: 0.6554\n",
      "Epoch [1/2], Step [90/901], Loss: 0.6929\n",
      "Epoch [1/2], Step [100/901], Loss: 0.6297\n",
      "Epoch [1/2], Step [110/901], Loss: 0.6621\n",
      "Epoch [1/2], Step [120/901], Loss: 0.6184\n",
      "Epoch [1/2], Step [130/901], Loss: 0.7423\n",
      "Epoch [1/2], Step [140/901], Loss: 0.6228\n",
      "Epoch [1/2], Step [150/901], Loss: 0.5819\n",
      "Epoch [1/2], Step [160/901], Loss: 0.6467\n",
      "Epoch [1/2], Step [170/901], Loss: 0.4878\n",
      "Epoch [1/2], Step [180/901], Loss: 0.6829\n",
      "Epoch [1/2], Step [190/901], Loss: 0.6726\n",
      "Epoch [1/2], Step [200/901], Loss: 0.7188\n",
      "Epoch [1/2], Step [210/901], Loss: 0.7239\n",
      "Epoch [1/2], Step [220/901], Loss: 0.5222\n",
      "Epoch [1/2], Step [230/901], Loss: 0.6743\n",
      "Epoch [1/2], Step [240/901], Loss: 0.5702\n",
      "Epoch [1/2], Step [250/901], Loss: 0.5307\n",
      "Epoch [1/2], Step [260/901], Loss: 0.6200\n",
      "Epoch [1/2], Step [270/901], Loss: 0.5387\n",
      "Epoch [1/2], Step [280/901], Loss: 0.6139\n",
      "Epoch [1/2], Step [290/901], Loss: 0.5326\n",
      "Epoch [1/2], Step [300/901], Loss: 1.0069\n",
      "Epoch [1/2], Step [310/901], Loss: 0.6909\n",
      "Epoch [1/2], Step [320/901], Loss: 0.5914\n",
      "Epoch [1/2], Step [330/901], Loss: 0.5779\n",
      "Epoch [1/2], Step [340/901], Loss: 0.6388\n",
      "Epoch [1/2], Step [350/901], Loss: 0.6331\n",
      "Epoch [1/2], Step [360/901], Loss: 0.7845\n",
      "Epoch [1/2], Step [370/901], Loss: 0.6997\n",
      "Epoch [1/2], Step [380/901], Loss: 0.7303\n",
      "Epoch [1/2], Step [390/901], Loss: 0.6827\n",
      "Epoch [1/2], Step [400/901], Loss: 0.5995\n",
      "Epoch [1/2], Step [410/901], Loss: 0.6784\n",
      "Epoch [1/2], Step [420/901], Loss: 0.5908\n",
      "Epoch [1/2], Step [430/901], Loss: 0.9840\n",
      "Epoch [1/2], Step [440/901], Loss: 0.7470\n",
      "Epoch [1/2], Step [450/901], Loss: 0.7216\n",
      "Epoch [1/2], Step [460/901], Loss: 0.6707\n",
      "Epoch [1/2], Step [470/901], Loss: 0.5616\n",
      "Epoch [1/2], Step [480/901], Loss: 0.6138\n",
      "Epoch [1/2], Step [490/901], Loss: 0.4047\n",
      "Epoch [1/2], Step [500/901], Loss: 0.5165\n",
      "Epoch [1/2], Step [510/901], Loss: 0.5801\n",
      "Epoch [1/2], Step [520/901], Loss: 0.5728\n",
      "Epoch [1/2], Step [530/901], Loss: 0.6126\n",
      "Epoch [1/2], Step [540/901], Loss: 0.6325\n",
      "Epoch [1/2], Step [550/901], Loss: 0.7004\n",
      "Epoch [1/2], Step [560/901], Loss: 0.6136\n",
      "Epoch [1/2], Step [570/901], Loss: 0.6024\n",
      "Epoch [1/2], Step [580/901], Loss: 0.7257\n",
      "Epoch [1/2], Step [590/901], Loss: 0.7258\n",
      "Epoch [1/2], Step [600/901], Loss: 0.5291\n",
      "Epoch [1/2], Step [610/901], Loss: 0.7156\n",
      "Epoch [1/2], Step [620/901], Loss: 0.6475\n",
      "Epoch [1/2], Step [630/901], Loss: 0.6386\n",
      "Epoch [1/2], Step [640/901], Loss: 0.5693\n",
      "Epoch [1/2], Step [650/901], Loss: 0.6240\n",
      "Epoch [1/2], Step [660/901], Loss: 0.6322\n",
      "Epoch [1/2], Step [670/901], Loss: 0.7388\n",
      "Epoch [1/2], Step [680/901], Loss: 0.6733\n",
      "Epoch [1/2], Step [690/901], Loss: 0.6814\n",
      "Epoch [1/2], Step [700/901], Loss: 0.6743\n",
      "Epoch [1/2], Step [710/901], Loss: 0.6590\n",
      "Epoch [1/2], Step [720/901], Loss: 0.6842\n",
      "Epoch [1/2], Step [730/901], Loss: 0.5438\n",
      "Epoch [1/2], Step [740/901], Loss: 0.8392\n",
      "Epoch [1/2], Step [750/901], Loss: 0.5363\n",
      "Epoch [1/2], Step [760/901], Loss: 0.6575\n",
      "Epoch [1/2], Step [770/901], Loss: 0.6689\n",
      "Epoch [1/2], Step [780/901], Loss: 0.7055\n",
      "Epoch [1/2], Step [790/901], Loss: 0.6392\n",
      "Epoch [1/2], Step [800/901], Loss: 0.7443\n",
      "Epoch [1/2], Step [810/901], Loss: 0.9419\n",
      "Epoch [1/2], Step [820/901], Loss: 0.4825\n",
      "Epoch [1/2], Step [830/901], Loss: 0.7896\n",
      "Epoch [1/2], Step [840/901], Loss: 0.7220\n",
      "Epoch [1/2], Step [850/901], Loss: 0.5306\n",
      "Epoch [1/2], Step [860/901], Loss: 0.7087\n",
      "Epoch [1/2], Step [870/901], Loss: 0.6792\n",
      "Epoch [1/2], Step [880/901], Loss: 0.7397\n",
      "Epoch [1/2], Step [890/901], Loss: 0.6286\n",
      "Epoch [1/2], Step [900/901], Loss: 0.5564\n",
      "Epoch [2/2], Step [10/901], Loss: 0.6931\n",
      "Epoch [2/2], Step [20/901], Loss: 0.5939\n",
      "Epoch [2/2], Step [30/901], Loss: 0.4400\n",
      "Epoch [2/2], Step [40/901], Loss: 0.5304\n",
      "Epoch [2/2], Step [50/901], Loss: 0.7179\n",
      "Epoch [2/2], Step [60/901], Loss: 0.4856\n",
      "Epoch [2/2], Step [70/901], Loss: 0.6518\n",
      "Epoch [2/2], Step [80/901], Loss: 0.6631\n",
      "Epoch [2/2], Step [90/901], Loss: 0.4789\n",
      "Epoch [2/2], Step [100/901], Loss: 0.5813\n",
      "Epoch [2/2], Step [110/901], Loss: 0.6322\n",
      "Epoch [2/2], Step [120/901], Loss: 0.7204\n",
      "Epoch [2/2], Step [130/901], Loss: 0.5726\n",
      "Epoch [2/2], Step [140/901], Loss: 0.5580\n",
      "Epoch [2/2], Step [150/901], Loss: 0.8843\n",
      "Epoch [2/2], Step [160/901], Loss: 0.5793\n",
      "Epoch [2/2], Step [170/901], Loss: 0.5297\n",
      "Epoch [2/2], Step [180/901], Loss: 0.7917\n",
      "Epoch [2/2], Step [190/901], Loss: 0.4912\n",
      "Epoch [2/2], Step [200/901], Loss: 0.7896\n",
      "Epoch [2/2], Step [210/901], Loss: 0.5902\n",
      "Epoch [2/2], Step [220/901], Loss: 0.5514\n",
      "Epoch [2/2], Step [230/901], Loss: 0.7583\n",
      "Epoch [2/2], Step [240/901], Loss: 0.6145\n",
      "Epoch [2/2], Step [250/901], Loss: 0.6987\n",
      "Epoch [2/2], Step [260/901], Loss: 0.5248\n",
      "Epoch [2/2], Step [270/901], Loss: 0.7451\n",
      "Epoch [2/2], Step [280/901], Loss: 0.5831\n",
      "Epoch [2/2], Step [290/901], Loss: 0.4979\n",
      "Epoch [2/2], Step [300/901], Loss: 0.8490\n",
      "Epoch [2/2], Step [310/901], Loss: 0.7246\n",
      "Epoch [2/2], Step [320/901], Loss: 0.6213\n",
      "Epoch [2/2], Step [330/901], Loss: 0.6150\n",
      "Epoch [2/2], Step [340/901], Loss: 0.6608\n",
      "Epoch [2/2], Step [350/901], Loss: 0.6479\n",
      "Epoch [2/2], Step [360/901], Loss: 0.3347\n",
      "Epoch [2/2], Step [370/901], Loss: 0.7033\n",
      "Epoch [2/2], Step [380/901], Loss: 0.6931\n",
      "Epoch [2/2], Step [390/901], Loss: 0.6492\n",
      "Epoch [2/2], Step [400/901], Loss: 0.7644\n",
      "Epoch [2/2], Step [410/901], Loss: 0.8116\n",
      "Epoch [2/2], Step [420/901], Loss: 0.7231\n",
      "Epoch [2/2], Step [430/901], Loss: 0.5018\n",
      "Epoch [2/2], Step [440/901], Loss: 0.5978\n",
      "Epoch [2/2], Step [450/901], Loss: 0.6145\n",
      "Epoch [2/2], Step [460/901], Loss: 0.6793\n",
      "Epoch [2/2], Step [470/901], Loss: 0.4800\n",
      "Epoch [2/2], Step [480/901], Loss: 0.5487\n",
      "Epoch [2/2], Step [490/901], Loss: 0.5649\n",
      "Epoch [2/2], Step [500/901], Loss: 0.6043\n",
      "Epoch [2/2], Step [510/901], Loss: 0.8382\n",
      "Epoch [2/2], Step [520/901], Loss: 0.6004\n",
      "Epoch [2/2], Step [530/901], Loss: 0.4994\n",
      "Epoch [2/2], Step [540/901], Loss: 0.6599\n",
      "Epoch [2/2], Step [550/901], Loss: 0.5143\n",
      "Epoch [2/2], Step [560/901], Loss: 0.7597\n",
      "Epoch [2/2], Step [570/901], Loss: 0.7252\n",
      "Epoch [2/2], Step [580/901], Loss: 0.8914\n",
      "Epoch [2/2], Step [590/901], Loss: 0.8679\n",
      "Epoch [2/2], Step [600/901], Loss: 0.6630\n",
      "Epoch [2/2], Step [610/901], Loss: 0.6473\n",
      "Epoch [2/2], Step [620/901], Loss: 0.6256\n",
      "Epoch [2/2], Step [630/901], Loss: 0.5824\n",
      "Epoch [2/2], Step [640/901], Loss: 0.6039\n",
      "Epoch [2/2], Step [650/901], Loss: 0.6440\n",
      "Epoch [2/2], Step [660/901], Loss: 0.7809\n",
      "Epoch [2/2], Step [670/901], Loss: 0.7317\n",
      "Epoch [2/2], Step [680/901], Loss: 0.6520\n",
      "Epoch [2/2], Step [690/901], Loss: 0.7831\n",
      "Epoch [2/2], Step [700/901], Loss: 0.6156\n",
      "Epoch [2/2], Step [710/901], Loss: 0.4806\n",
      "Epoch [2/2], Step [720/901], Loss: 0.4927\n",
      "Epoch [2/2], Step [730/901], Loss: 0.6139\n",
      "Epoch [2/2], Step [740/901], Loss: 0.6786\n",
      "Epoch [2/2], Step [750/901], Loss: 0.7103\n",
      "Epoch [2/2], Step [760/901], Loss: 0.7376\n",
      "Epoch [2/2], Step [770/901], Loss: 0.5662\n",
      "Epoch [2/2], Step [780/901], Loss: 0.5186\n",
      "Epoch [2/2], Step [790/901], Loss: 0.6615\n",
      "Epoch [2/2], Step [800/901], Loss: 0.5762\n",
      "Epoch [2/2], Step [810/901], Loss: 0.5186\n",
      "Epoch [2/2], Step [820/901], Loss: 0.6491\n",
      "Epoch [2/2], Step [830/901], Loss: 0.7224\n",
      "Epoch [2/2], Step [840/901], Loss: 0.6580\n",
      "Epoch [2/2], Step [850/901], Loss: 0.8275\n",
      "Epoch [2/2], Step [860/901], Loss: 0.4591\n",
      "Epoch [2/2], Step [870/901], Loss: 0.5723\n",
      "Epoch [2/2], Step [880/901], Loss: 0.6163\n",
      "Epoch [2/2], Step [890/901], Loss: 0.8212\n",
      "Epoch [2/2], Step [900/901], Loss: 0.4889\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 10 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "colab_type": "code",
    "id": "DF5GHv631kpg",
    "outputId": "deb73c00-50fd-4e5a-8b82-261c3d3ac8fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "10\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'argmax'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-9fe0c6987f91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mval_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \"\"\"\n\u001b[0;32m-> 1103\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# a downstream library like 'pandas'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: bool value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "Predictions=[]\n",
    "# Test the model\n",
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        Predictions.append(predicted)\n",
    "         \n",
    "    print(len(Predictions))\n",
    "    print(len(Predictions[0]))\n",
    "    print(Predictions[0])\n",
    "    \n",
    "from sklearn.metrics import classification_report\n",
    "val_preds = np.argmax(Predictions, axis=-1)\n",
    "print(classification_report(labels, val_preds))\n",
    " \n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9r9HFMXz1kpo",
    "outputId": "1c9847d2-317f-4237-d7ee-b86784bc59f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 53.6 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SIGMA_ASSIGNMENT1_Resnet18_Cats_Dogs_Pytorch.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
